# Chapter 5. 카프카 실전 프로젝트
## 5.1 웹 페이지 이벤트 적재 파이프라인 생성
<img width="360" height="203" alt="image" src="https://github.com/user-attachments/assets/76be6856-43b9-460a-bb08-9e642c0b5073" />
- 이벤트 수집은 서비스에 영향을 미치지 않아야 한다.
- 여기서는 웹 페이지에서 생성되는 이벤트들을 분석하기 위해 HDFS와 엘라스틱서치에 적재하는 파이프라인을 만드는 프로젝트를 진행한다.


### 5.1.1 요구사항
- 이름을 입력하고 좋아하는 색상 고르면 유저 에이전트 정보를 카프카 토픽으로 전달하고 하둡과 엘라스틱서치에 적재
- `하둡`은 대용량 데이터를 분석 처리 / `HDFS`는 대용량 파일을 하둡에 안정적으로 저장할 수 있게 하는 파일 시스템

### 5.1.2 정책 및 기능 정의
#### 적재 정책
- 적재 파이프라인을 만들 때 가장 처음 결정해야 하는 게 적재 정책
- 파이프라인의 운영 난이도는 정책에 따라 달라진다.
- 0.11.0.0 이후 버전부터는 멱등성 프로듀서를 통해 **정확히 한번 전달**을 지원한다.
  
- 전달 : 프로듀서부터 브로커까지 전달되는 것
- 적재 : 프로듀서부터 컨슈머를 넘어 최종적으로 하둡이나 엘라스틱서치까지 데이터가 저장되는 것
- 컨슈머의 커밋 시점과 데이터 적재가 동일 트랜잭션에서 처리되어야 정확히 한 번 적재될 수 있긴 함
  - HDFS 적재, S3 적재 컨슈머 애플리케이션에서는 컨슈머의 커밋과 저장이 동일 트랜잭션으로 처리하는 것이 불가능하다
  - 그렇기 때문에 HDFS 적재, S3 적재 컨슈머 애플리케이션은 컨슈머의 장애가 발생하면 정확히 한번 적재하지 못한다.
- 정확히 한번 적재가 필요한 경우 멱등성 프로듀서 사용하고 고유한 키를 지원하는 DBMS 사용하는 게 가장 확실

- 웹 페이지 이벤트 수집은 유실 발생 가능 & 중복 발생 가능
- 따라서 파이프라인은 다음과 같이 정리된다.
  - 일부 데이터의 유실 또는 중복 허용
  - 안정적으로 끊임없는 적재
  - 갑작스럽게 발생하는 많은 데이터양을 허용

#### 데이터 포맷
- 데이터 파이프라인에서 데이터를 담는 용도로 사용되는 데이터 포맷은 매우 다양한 선택지가 있다.
-  VO(Value Object) 형태로 객체를 선언하여 직렬화하여 전송하는 방법
  - 보편적이지만 프로듀서와 컨슈머에서 동일한 버전의 VO 객체 선언 필요
  - 스키마가 변경될 경우 프로듀서와 컨슈머 둘 다 소스코드 업데이트가 필요하므로 비용이 크다.
- 데이터 포맷 선택할 때 생각해볼 수 있는 것
  - 스키마의 변화의 유연성
  - 명령어를 통한 디버깅의 편리성
- JSON 선택
#### 웹페이지
- html 사용

#### 프로듀서
- 웹 페이지에서 생성된 이벤트를 받는 REST API 클라이언트를 만들고 전달받은 이벤트를 가공하여 토픽으로 전달하는 역할을 한다.
- REST API는 스프링 부트 + RestController 사용해 개발
- RestController로 받은 데이터를 토픽으로 전달할 때는 스프링 카프카 라이브러리 사용
➡️ RestController로 REST API를 받는 메서드를 만들고 스프링 카프카의 KafkaTemplate로 프로듀서를 구현하여 데이터를 전송한다.

- **acks는 어떤 값으로 설정할 것인가?**
  - all : 클러스터 또는 네트워크에 이상이 생겼을 경우 복구 확률이 가장 높지만 데이터 저장하는데 오래 걸림
  - 1 또는 0 : 속도는 빠르지만 데이터 유실 발생 가능
-> 우리는 유실이 발생하더라도 안정적이고 빠른 파이프라인이 우선이므로 1로 설정

- **최소 동기화 리플리카는 어떻게 설정할 것인가?**
  - acks 1로 설정 시 min.insync.replicas 설정을 무시하고 리더 파티션에 지속 적재하므로 따로 설정할 필요가 없다.
