# Chapter 3. 카프카 기본 개념 설명

## 3.1. 카프카 브로커, 클러스터, 주키퍼
- 카프카 브로커 : 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 데이터를 안전하게 보관, 처리하기 위해 **3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다**
- 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장 및 복제하는 역할을 수행한다

### 데이터 저장, 전송
- 카프카는 `페이지 캐시` 를 사용해서 디스크 입출력 속도를 높여 파일 시스템의 처리 속도가 느린 문제를 해결했다
  - 페이지 캐시 : OS 에서 파일 입출력의 성능 향상을 위해 만들어 놓은 `메모리` 영역
  - 한번 읽은 파일 내용은 메모리의 페이지 캐시 영역에 저장한다. <br>
  추후 동일 파일 접근이 일어나면 **디스크에서 읽지 않고 메모리에서 직접 읽는다.**

### 데이터 복제, 싱크
- 카프카 데이터 복제는 `파티션` 단위로 이루어진다
- 복제 개수 최솟값은 1 (복제 없음), 최댓값은 브로커 개수만큼 설정가능
- 복제 개수가 3인 경우
![](image0.png)
- 복제된 파티션은 `리더` 와 `팔로워` 로 구성된다
    - 리더 : 프로듀서 또는 컨슈머와 직접 통신하는 파티션
    - 팔로워 : 나머지 복제 데이터를 가지고 있는 파티션
      - 리더 파티션의 오프셋을 확인하여, 현재 자신이 가진 오프셋과 차이가 나면 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장 => 복제
      - 복제 개수만큼 저장용량이 증가한다는 단점 vs. 데이터를 안전하게 사용할 수 있다는 강력한 장점

### 컨트롤러(controller)
- 컨트롤러는 다른 브로커들의 상태를 체크하고, 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 분배한다

### 데이터 삭제
- 카프카는 타 메시징 플랫폼과 달리, 컨슈머가 데이터를 가져가도 토픽의 데이터는 삭제되지 않으며 컨슈머/프로듀서가 데이터 삭제를 요청할 수도 없으며 **오직 브로커만이 데이터를 삭제할 수 있다**

![alt text](/Chapter%2002/은주/image.png)

### 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 **파티션의 어느 레코드까지 가져간지 확인하기 위해 오프셋을 커밋한다**
  - 여기서 저장된 오프셋을 토대로, 컨슈머 그룹은 다음 레코드를 가져가 처리한다

### 코디네이터(coordinator)
- 클러스터의 **다수 브로커 중 한 대는 코디네이터 역할을 수행한다**
  - 코디네이터 : **컨슈머 그룹의 상태를 체크, 파티션을 컨슈머와 매칭되도록 분배**
    - 컨슈머가 컨슈머 그룹에서 빠지면, 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터 처리되도록 도움
    - 리밸런스 : 파티션을 컨슈머로 재할당하는 과정
- 주키퍼 : 카프카의 메타데이터를 관리하는데에 사용됨
- __consumer__offsets 토픽 : 카프카 내부에서 컨슈머 오프셋을 저장하기 위한 용도로 사용되는 토픽
![alt text](image.png)
- 카프카 클러스터로 묶인 브로커들은 동일한 주키퍼 경로 (zookeeper.connect 옵션) 를 사용해야 하며, 그렇게 해야 주키퍼가 같은 카프카 클러스터에 속한 브로커들로 인식한다. 

## 3.2. 토픽과 파티션
- 토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위
- 파티션은 카프카의 `병렬 처리의 핵심` 으로써, 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭됨
- 컨슈머 처리가 한정된 상황에서, 컨슈머 개수 + 파티션 개수를 늘리면 스케일 아웃 가능
- 파티션의 레코드는 **컨슈머가 가져가는 것과 별개로 관리되므로, 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 가져갈 수 있다**

![alt text](image-1.png)
|항목|가능 여부|
|------|---|
|하나의 파티션을 여러 컨슈머가 읽기 (같은 group)	|❌	불가능 |
|하나의 파티션을 여러 컨슈머가 읽기 (다른 group)	|✅	가능|
|하나의 컨슈머가 여러 파티션을 소비	|✅	일반적인 구조|

## 3.3. 레코드
- 레코드
  - 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성
- 타임스탬프
  - 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이 결정됨
- 메시지 키
  - 메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 때 **메시지 키의 해시값을 토대로 파티션을 지정**하게 된다.
    - 즉, 동일한 메시지 키라면 동일 파티션에 들어가게 된다. 
  - 메시지키가 null 로 설정된 레코드는 프로듀서 기본 설정 파티셔너에 따라서 파티션에 분배되어 저장된다.

  > ```java
  > public CompletableFuture<SendResult<K, V>> send(String topic, K key, @Nullable V data)
  > ```
  > - 여기서 K key는 Kafka 메시지의 "Key", 즉 파티션을 결정짓는 기준이 되는 메시지 키
  > - 메시지키를 랜덤값으로 사용할 경우 **의도적으로 랜덤 파티션 분산이 가능**하다

- 메시지 값
   - 실질적으로 처리할 데이터가 들어있으며, **메시지 키와 메시지 값은 직렬화**되어 (ex. ProducerRecord / ConsumerRecord) 브로커로 전송되기 때문에 컨슈머가 이용할 때는 직렬화한 형태와 동일한 형태로 역직렬화를 수행해야 한다. 
- 레코드 오프셋
  - 0 이상의 숫자로, 직접 지정할 수 없고 **브로커에 저장될 때 이전에 전송된 레코드의 오프셋+1 값으로 생성된다.**
  - 오프셋을 사용하면 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를 어디까지 가져갔는지 명확히 지정할 수 있다.
```json
Record = {
  topic: "example-topic",
  partition: 0,
  offset: 12345,
  timestamp: 1680000000000,
  key: "some-key",
  value: "some-value",
  headers: [ { key: "correlation-id", value: "abc123" } ]
}
```

## 3.4. 카프카 클라이언트