# Chapter 3. 카프카 기본 개념 설명

## 3.1. 카프카 브로커, 클러스터, 주키퍼
- 카프카 브로커 : 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 데이터를 안전하게 보관, 처리하기 위해 **3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다**
- 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장 및 복제하는 역할을 수행한다

### 데이터 저장, 전송
- 카프카는 `페이지 캐시` 를 사용해서 디스크 입출력 속도를 높여 파일 시스템의 처리 속도가 느린 문제를 해결했다
  - 페이지 캐시 : OS 에서 파일 입출력의 성능 향상을 위해 만들어 놓은 `메모리` 영역
  - 한번 읽은 파일 내용은 메모리의 페이지 캐시 영역에 저장한다. <br>
  추후 동일 파일 접근이 일어나면 **디스크에서 읽지 않고 메모리에서 직접 읽는다.**

### 데이터 복제, 싱크
- 카프카 데이터 복제는 `파티션` 단위로 이루어진다
- 복제 개수 최솟값은 1 (복제 없음), 최댓값은 브로커 개수만큼 설정가능
- 복제 개수가 3인 경우
![](image0.png)
- 복제된 파티션은 `리더` 와 `팔로워` 로 구성된다
    - 리더 : 프로듀서 또는 컨슈머와 직접 통신하는 파티션
    - 팔로워 : 나머지 복제 데이터를 가지고 있는 파티션
      - 리더 파티션의 오프셋을 확인하여, 현재 자신이 가진 오프셋과 차이가 나면 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장 => 복제
      - 복제 개수만큼 저장용량이 증가한다는 단점 vs. 데이터를 안전하게 사용할 수 있다는 강력한 장점

### 컨트롤러(controller)
- 컨트롤러는 다른 브로커들의 상태를 체크하고, 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 분배한다

### 데이터 삭제
- 카프카는 타 메시징 플랫폼과 달리, 컨슈머가 데이터를 가져가도 토픽의 데이터는 삭제되지 않으며 컨슈머/프로듀서가 데이터 삭제를 요청할 수도 없으며 **오직 브로커만이 데이터를 삭제할 수 있다**

![alt text](/Chapter%2002/은주/image.png)

### 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 **파티션의 어느 레코드까지 가져간지 확인하기 위해 오프셋을 커밋한다**
  - 여기서 저장된 오프셋을 토대로, 컨슈머 그룹은 다음 레코드를 가져가 처리한다

### 코디네이터(coordinator)
- 클러스터의 **다수 브로커 중 한 대는 코디네이터 역할을 수행한다**
  - 코디네이터 : **컨슈머 그룹의 상태를 체크, 파티션을 컨슈머와 매칭되도록 분배**
    - 컨슈머가 컨슈머 그룹에서 빠지면, 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터 처리되도록 도움
    - 리밸런스 : 파티션을 컨슈머로 재할당하는 과정
- 주키퍼 : 카프카의 메타데이터를 관리하는데에 사용됨
- __consumer__offsets 토픽 : 카프카 내부에서 컨슈머 오프셋을 저장하기 위한 용도로 사용되는 토픽
![alt text](image.png)
- 카프카 클러스터로 묶인 브로커들은 동일한 주키퍼 경로 (zookeeper.connect 옵션) 를 사용해야 하며, 그렇게 해야 주키퍼가 같은 카프카 클러스터에 속한 브로커들로 인식한다. 

## 3.2. 토픽과 파티션
- 토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위
- 파티션은 카프카의 `병렬 처리의 핵심` 으로써, 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭됨
- 컨슈머 처리가 한정된 상황에서, 컨슈머 개수 + 파티션 개수를 늘리면 스케일 아웃 가능
- 파티션의 레코드는 **컨슈머가 가져가는 것과 별개로 관리되므로, 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 가져갈 수 있다**

![alt text](image-1.png)
|항목|가능 여부|
|------|---|
|하나의 파티션을 여러 컨슈머가 읽기 (같은 group)	|❌	불가능 |
|하나의 파티션을 여러 컨슈머가 읽기 (다른 group)	|✅	가능|
|하나의 컨슈머가 여러 파티션을 소비	|✅	일반적인 구조|

## 3.3. 레코드
- 레코드
  - 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성
- 타임스탬프
  - 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이 결정됨
- 메시지 키
  - 메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 때 **메시지 키의 해시값을 토대로 파티션을 지정**하게 된다.
    - 즉, **동일한 메시지 키라면 동일 파티션에 들어가게 된다.**
  - 메시지키가 null 로 설정된 레코드는 프로듀서 기본 설정 파티셔너에 따라서 파티션에 분배되어 저장된다.

  > ```java
  > public CompletableFuture<SendResult<K, V>> send(String topic, K key, @Nullable V data)
  > ```
  > - 여기서 K key는 Kafka 메시지의 "Key", 즉 파티션을 결정짓는 기준이 되는 메시지 키
  > - 메시지키를 랜덤값으로 사용할 경우 **의도적으로 랜덤 파티션 분산이 가능**하다

- 메시지 값
   - 실질적으로 처리할 데이터가 들어있으며, **메시지 키와 메시지 값은 직렬화**되어 (ex. ProducerRecord / ConsumerRecord) 브로커로 전송되기 때문에 컨슈머가 이용할 때는 직렬화한 형태와 동일한 형태로 역직렬화를 수행해야 한다. 
- 레코드 오프셋
  - 0 이상의 숫자로, 직접 지정할 수 없고 **브로커에 저장될 때 이전에 전송된 레코드의 오프셋+1 값으로 생성된다.**
  - 오프셋을 사용하면 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를 어디까지 가져갔는지 명확히 지정할 수 있다.
```json
Record = {
  topic: "example-topic",
  partition: 0,
  offset: 12345,
  timestamp: 1680000000000,
  key: "some-key",
  value: "some-value",
  headers: [ { key: "correlation-id", value: "abc123" } ]
}
```

## 3.4. 카프카 클라이언트
### 3.4.1. 프로듀서 API
- 프로듀서는 데이터를 전송할 때 **리더 파티션을 가지고 있는 카프카 브로커와 직접 통신**한다

#### 카프카 프로듀서 프로젝트 생성
```java
KafkaProducer<String, String> producer = new KafkaProducer<String, String>(configs);

String messageKey = "key1";
String messageValue = "testMessage";
ProducerRecord<String, String> record = new ProducerRecord(TOPIC_NAME, messageKey, messageValue);
producer.send(record); // A
producer.flush(); // B
```
- A: send() 메서드는 즉각적인 전송을 뜻하는 것이 아니라, **파라미터로 들어간 record를 프로듀서 내부에 가지고 있다가, 배치 형태로 묶어서 브로커에 전송**한다. 
  - 이러한 전송 방식을 '배치 전송' 이라고 부른다. 
  - 배치 전송을 통해 카프카는 타 메시지 플랫폼과 차별화된 전송 속도를 가지게 되었다.
- B: flush() 메서드는 **프로듀서 내부 버퍼에 가지고 있던 레코드 배치를 브로커로 전송**한다.

#### 프로듀서 중요 개념
![alt text](image-2.png)
- KafkaProducer 인스턴스가 `send()` 메서드를 호출하면, ProducerRecord는 **파티셔너(partitioner)에서 토픽의 어느 파티션으로 전송될 것인지 정해진다.**
- 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 **어큐뮬레이터(accumulator)에 데이터를 버퍼로 쌓아놓고 발송**한다.
  - 버퍼로 쌓인 데이터는 **배치**로 묶어서 전송함으로써 카프카의 프로듀서 처리량을 향상시키는데 도움을 준다.
- 카프카 클라이언트 라이브러리 2.5.0 버전에서 파티셔너를 지정하지 않은 경우 UniformStickyPartitioner 가 기본 파티셔너로 설정된다.
  - UniformStickyPartitioner, RoundRobinPartitioner 파티셔너의 공통점 : 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 데이터를 전송한다는 점이다.
- 카프카 2.4.0 이전에는 RoundRobinPartitioner가 기본 파티셔너로 설정되어 있었다.
  - **ProducerRecord가 들어오는 대로 파티션을 순회하면서 전송하기 때문에 배치로 묶이는 빈도가 적다.**
  - 될 수 있으면 많은 데이터가 배치로 묶여 전송되어야 성능 향상을 기대할 수 있으므로, 카프카 2.4.0부터는 UniformStickyPartitioner가 기본 파티셔너로 설정되었다.
- UniformStickyPartitioner
  - 프로듀서 동작에 특화되어 높은 처리량과 낮은 리소스 사용률을 가진다.
  - **어큐뮬레이터에서 데이터가 배치로 모두 묶일 때까지 기다렸다가 배치로 묶인 데이터는 모두 동일한 파티션에 전송**함으로써 RoundRobinPartitioner에 비해 향상된 성능을 가지게 되었다.
- Partitioner 인터페이스를 상속받은 사용자 정의 클래스에서 메시지 키 또는 메시지 값에 따라 파티션 지정 로직을 지정할 수 있다.
> 그러나, 카프카 버전 3.3 부터는 DefaultPartitioner, UniformStickyPartitioner는 deprecated됨
- 프로듀서는 압축 옵션을 통해 브로커로 전송 시 압축 방식을 정할 수 있다. ex) gzip, snappy, lz4, zstd 를 지원
- 압축을 하면 데이터 전송 시 네트워크 처리량에 이득을 볼 수 있지만, 압축을 하는데에 CPU 나 메모리 리소스를 사용하므로 사용환경에 따라 적절한 압축 옵션을 사용하는 것이 중요하다.

#### 프로듀서 주요 옵션
- 필수 옵션
  - `bootstrap.servers` : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트 를 1개 이상 작성
  - `key.serializer` : 레코드의 메시지 키를 직렬화하는 클래스
  - `value.serializer` : 레코드의 메시지 값을 직렬화하는 클래스
- 선택 옵션
  - `acks` : 프로듀서가 전송한 데이터가 **브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는데 사용하는 옵션**
    - 1 : 기본값. 리더 파티션에 데이터가 저장되면 전송 성공으로 판단.
    - 0 : 프로듀서가 전송한 즉시, 브로커에 데이터 저장 여부 상관없이 성공으로 판단.
    - -1 (all) : 토픽의 min.insync.replicas 개수에 해당하는 리더 파티션, 팔로워 파티션에 데이터가 저장되면 성공으로 판단.
  - `buffer.memory` : 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리양 지정. 기본값은 32MB(33554432)
  - `retries` : 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송 시도 횟수. 기본값은 2147483647
  - `batch.size` : 배치로 전송할 레코드 최대 용량. 너무 작게 설정하면 프로듀서가 브로커로 더 자주 보내기 때문에 네트워크 부담이 있고, 너무 크게 설정하면 메모리를 더 많이 사용하게 되는 점을 주의. 기본값은 16384.
  - `linger.ms` : 배치를 전송하기 전까지 기다리는 최소 시간. 기본값은 0.
  - `partitioner.class` : 레코드를 파티션에 전송할 때, 적용하는 파티션 클래스 지정. 기본값은 DefaultPartitioner
  - `enable.idempotence` : 멱등성 프로듀서로 동작할 지 여부 설정. 기본값 false.
  - `transactional.id` : 프로듀서가 레코드를 전송할 때, 레코드를 트랜잭션 단위로 묶을지 설정. 프로듀서의 고유한 트랜잭션 id를 설정할 수 있다. 이 값을 설정하면 트랜잭션 프로듀서로 동작한다.

#### 브로커 정상 전송 여부를 확인하는 프로듀서
- KakfaProducer.send() 메서드는 Future 객체를 반환하는데, 이는 RecordMetatdata 의 비동기 결과를 표현한다
- send() 의 결과값은 **카프카 브로커로부터 응답을 기다렸다가, 브로커로부터 응답이 오면 RecordMetatdata 인스턴스를 반환**한다
- 프로듀서는 비동기로 결과를 확인할 수 있도록 callback 인터페이스를 제공한다. 따라서 비동기로 결과를 받으려면 ProducerRecord 객체와 함께 사용자 정의 callback 클래스를 넣으면 된다
  ```java
  // kafkaTemplate
  Future<RecordMetadata> sendFuture = producer.send(producerRecord, this.buildCallback(producerRecord, producer, future, sample, observation));
  ```

## 3.4.2. 컨슈머 API
### 컨슈머 중요 개념
- 토픽의 파티션으로부터 데이터를 가져가기 위해 컨슈머 운영하는 방법
  - 1개 이상의 컨슈머로 이루어진 **컨슈머 그룹** 운영하기
  - 토픽의 **특정 파티션만 구독하는 컨슈머** 운영하기
- 컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다
![alt text](image-3.png)